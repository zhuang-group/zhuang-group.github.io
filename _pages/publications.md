---
layout: archive
title: ""
permalink: /publications/
author_profile: true
---

(Selected Publications. \* equal contribution, \# corresponding author)

**2023**

- **QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models**

**Jing Liu**, Ruihao Gong, Xiuying Wei, Zhiwei Dong, Jianfei Cai, Bohan Zhuang\#

[[Paper](https://arxiv.org/abs/2310.08041)]


- **LoRAPrune: Pruning Meets Low-Rank Parameter-Efficient Fine-Tuning**

**Mingyang Zhang**, Hao Chen, Chunhua Shen, Zhen Yang, Linlin Ou, Xinyi Yu, Bohan Zhuang

[[Paper](https://arxiv.org/abs/2305.18403v3)]


- **EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models**

**Yefei He**, Jing Liu, Weijia Wu, Hong Zhou\#, Bohan Zhuang\#

[[Paper](https://arxiv.org/abs/2310.03270)]


- **Stitched ViTs are Flexible Vision Backbones**
  
**Zizheng Pan**, Jing Liu, Haoyu He, Jianfei Cai, Bohan Zhuang\#

[[Paper](https://arxiv.org/abs/2307.00154)]


- **PTQD: Accurate Post-Training Quantization for Diffusion Models**

**Yefei He**, Luping Liu, Jing Liu, Weijia Wu, Hong Zhou\#, Bohan Zhuang\#

[[Paper](https://arxiv.org/pdf/2305.10657.pdf)] **NeurIPS 2023**


- **Mask Propagation for Efficient Video Semantic Segmentation**

**Yuetian Weng**, Mingfei Han, Haoyu He, Mingjie Li, Xiaojun Chang, Bohan Zhuang\#

[[Paper]()]  **NeurIPS 2023**


- **Second-Order Degradation and Reconstruction for Test-Time Image Super-Resolution**

**Zeshuai Deng**, Zhuokun Chen, Shuaicheng Niu, Thomas H. Li, Bohan Zhuang\#, Mingkui Tan\#

[[Paper]()]  **NeurIPS 2023**


- **Sensitivity-Aware Visual Parameter-Efficient Fine-Tuning**

**Haoyu He**, Jianfei Cai, Jing Zhang, Dacheng Tao, Bohan Zhuang\#

[[Paper](https://arxiv.org/abs/2303.08566)][[Code](https://github.com/ziplab/SPT)] **ICCV 2023 (Oral)**


- **BiViT: Extremely Compressed Binary Vision Transformer**

**Yefei He**, Zhenyu Lou, Luoming Zhang, Weijia Wu, Hong Zhou\#, Bohan Zhuang\#

[[Paper](https://arxiv.org/pdf/2211.07091.pdf)] **ICCV 2023**


- **Stitchable Neural Networks**

**Zizheng Pan**, Jianfei Cai, Bohan Zhuang\#

[[Paper](https://arxiv.org/abs/2302.06586)][[Project](https://snnet.github.io/)][[Code](https://github.com/ziplab/SN-Net)] **CVPR 2023 (Highlight, Top 2.5%)** 


- **Dynamic Focus-aware Positional Queries for Semantic Segmentation**

**Haoyu He**, Jianfei Cai, Zizheng Pan, Jing Liu, Jing Zhang, Dacheng Tao, Bohan Zhuang\#

[[Paper](https://arxiv.org/abs/2204.01244)][[Code](https://github.com/ziplab/FASeg)] **CVPR 2023**


- **Single-path Bit Sharing for Automatic Loss-aware Model Compression**

**Jing Liu**, Bohan Zhuang, Peng Chen, Chunhua Shen, Jianfei Cai, Mingkui Tan

[[Paper](https://arxiv.org/abs/2101.04935)]  **TPAMI 2023**


- **End-to-end One-shot Human Parsing**

**Haoyu He**, Jing Zhang, Bohan Zhuang, Jianfei Cai, Dacheng Tao

[[Paper](https://arxiv.org/abs/2105.01241)][[Code](https://github.com/Charleshhy/One-shot-Human-Parsing/stargazers)] **TPAMI 2023**


- **A Survey on Efficient Training of Transformers**

**Bohan Zhuang**\#, Jing Liu, Zizheng Pan, Haoyu He, Yuetian Weng, Chunhua Shen

[[Paper](https://arxiv.org/abs/2302.01107)] **IJCAI 2023 Survey Track**



**2022**

- **EcoFormer: Energy-Saving Attention with Linear Complexity**  

**Jing Liu**\*, **Zizheng Pan**\*, Haoyu He, Jianfei Cai, Bohan Zhuang\#

[[Paper](https://openreview.net/forum?id=MK_130d4Y0)][[Code](https://github.com/ziplab/EcoFormer)]  **NeurIPS 2022 (Spotlight, Top 3%)**  


- **Fast Vision Transformers with HiLo Attention**

**Zizheng Pan**, Jianfei Cai, Bohan Zhuang\#

[[Paper](https://openreview.net/forum?id=Pyd6Rh9r1OT)][[Code](https://github.com/ziplab/LITv2)]  **NeurIPS 2022 (Spotlight, Top 3%)**




- **An Efficient Spatio-Temporal Pyramid Transformer for Action Detection**

**Yuetian Weng**, Zizheng Pan, Mingfei Han, Xiaojun Chang, Bohan Zhuang\#

[[Paper](https://link.springer.com/content/pdf/10.1007/978-3-031-19830-4_21.pdf)][[Code](https://github.com/ziplab/STPT)]   **ECCV 2022**



- **Automated Progressive Learning for Efficient Training of Vision Transformers**

**Changlin Li**, Bohan Zhuang\#, Guangrun Wang, Xiaodan Liang, Xiaojun Chang, Yi Yang

[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Automated_Progressive_Learning_for_Efficient_Training_of_Vision_Transformers_CVPR_2022_paper.pdf)][[Code](https://github.com/changlin31/AutoProg)]  **CVPR 2022**


- **Less is More: Pay Less Attention in Vision Transformers**

**Zizheng Pan**, Bohan Zhuang\#, Haoyu He, Jing Liu, Jianfei Cai

[[paper](https://ojs.aaai.org/index.php/AAAI/article/view/20099)] [[Code](https://github.com/zhuang-group/LIT)] **AAAI 2022**



- **Structured Binary Neural Networks for Image Recognition**

**Bohan Zhuang**, Chunhua Shen, Mingkui Tan, Peng Chen, Lingqiao Liu, Ian Reid

[[paper](https://link.springer.com/article/10.1007/s11263-022-01638-0)]  **IJCV 2022**


- **Pruning Self-attentions into Convolutional Layers in Single Path**

**Haoyu He**, Jing Liu, Zizheng Pan, Jianfei Cai, Jing Zhang, Dacheng Tao, Bohan Zhuang\#

[[Paper](https://arxiv.org/abs/2111.11802)][[Code](https://github.com/zip-group/SPViT)]


- **Mesa: A Memory-saving Training Framework for Transformers**

**Zizheng Pan**, Peng Chen, Haoyu He, Jing Liu, Jianfei Cai, Bohan Zhuang\#

[[Paper](https://arxiv.org/abs/2111.11124)][[Code](https://github.com/zip-group/Mesa)]



- **Sharpness-aware Quantization for Deep Neural Networks**

**Jing Liu**, Jianfei Cai, Bohan Zhuang\#

[[Paper](https://arxiv.org/abs/2111.12273)][[Code](https://github.com/zip-group/SAQ)]


- **FocusFormer: Focusing on What We Need via Architecture Sampler**

**Jing Liu**, Jianfei Cai, Bohan Zhuang\#

[[Paper](https://arxiv.org/abs/2208.10861)]


- **Rapid Elastic Architecture Search under Specialized Classes and Resource Constraints**

**Jing Liu**, Bohan Zhuang\#, Mingkui Tan, Xu Liu, Dinh Phung, Yuanqing Li, Jianfei Cai

[[Paper](https://arxiv.org/abs/2108.01224)]




**2021**


- **Scalable Vision Transformers with Hierarchical Pooling**

**Zizheng Pan**, Bohan Zhuang\#, **Jing Liu**, **Haoyu He**, Jianfei Cai

[[Paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Pan_Scalable_Vision_Transformers_With_Hierarchical_Pooling_ICCV_2021_paper.pdf)][[Code](https://github.com/zhuang-group/HVT)]  **ICCV 2021**


- **FATNN: Fast and Accurate Ternary Neural Networks**

**Peng Chen**\*,  Bohan Zhuang\*, Chunhua Shen

[[Paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_FATNN_Fast_and_Accurate_Ternary_Neural_Networks_ICCV_2021_paper.pdf)][[Code](https://github.com/zhuang-group/QTool)]   **ICCV 2021**


- **Effective Training of Convolutional Neural Networks with Low-bitwidth Weights and Activations**

**Bohan Zhuang**\*, Mingkui Tan\*, **Jing Liu**\*, Ian Reid, Chunhua Shen\#

[[Paper](https://arxiv.org/pdf/1908.04680.pdf)][[Code](https://github.com/bohanzhuang/Towards-Effective-Low-bitwidth-Convolutional-Neural-Networks)] **TPAMI**


- **Discrimination-aware Network Pruning for Deep Model Compression**

**Jing Liu**\*, Bohan Zhuang\*, Zhuangwei Zhuang\*, Yong Guo, Junzhou Huang, Jinhui Zhu, Mingkui Tan\#

[[Paper](https://ieeexplore.ieee.org/document/9384353)][[Code](https://github.com/SCUT-AILab/DCP)] **TPAMI**


- **AQD: Towards Accurate Quantized Object Detection**

**Peng Chen**\*, **Jing Liu**\*, Bohan Zhuang\#, Mingkui Tan, Chunhua Shen

[[Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_AQD_Towards_Accurate_Quantized_Object_Detection_CVPR_2021_paper.pdf)][[Code](https://github.com/zhuang-group/QTool)]  **CVPR 2021 (Oral)**


- **SA-BNN: State-Aware Binary Neural Network**

Chunlei Liu\*, **Peng Chen**\*, Bohan Zhuang\*, Chunhua Shen, Baochang Zhang, Wenrui Ding

[[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/16306)] **AAAI 2021**







