---
layout: archive
title: ""
permalink: /publications/
author_profile: true
---

(Selected Publications. \* equal contribution, \# corresponding author)

**2024**


- **MVSplat: Efficient 3D Gaussian Splatting from Sparse Multi-View Images**

**Yuedong Chen**, Haofei Xu, Chuanxia Zheng, Bohan Zhuang, Marc Pollefeys, Andreas Geiger, Tat-Jen Cham, Jianfei Cai

[[Paper](https://arxiv.org/abs/2403.14627)][[Project](https://donydchen.github.io/mvsplat/)][[Code](https://github.com/donydchen/mvsplat)]


- **T-Stitch: Accelerating Sampling in Pre-Trained Diffusion Models with Trajectory Stitching**

**Zizheng Pan**, Bohan Zhuang\#, De-An Huang, Weili Nie, Zhiding Yu, Chaowei Xiao, Jianfei Cai, Anima Anandkumar

[[Paper](https://arxiv.org/abs/2402.14167)][[Project](https://t-stitch.github.io/)][[Code](https://github.com/NVlabs/T-Stitch)]


- **LongVLM: Efficient Long Video Understanding via Large Language Models**
  
**Yuetian Weng**, Mingfei Han, Haoyu He, Xiaojun Chang, Bohan Zhuang

[[Paper](https://arxiv.org/abs/2404.03384)]

  
- **LoRAPrune: Pruning Meets Low-Rank Parameter-Efficient Fine-Tuning**

**Mingyang Zhang**, Hao Chen, Chunhua Shen, Zhen Yang, Linlin Ou, Xinyi Yu, Bohan Zhuang

[[Paper](https://arxiv.org/abs/2305.18403v3)] ACL 2024 Findings


- **Stitched ViTs are Flexible Vision Backbones** (SN-Net v2)
  
**Zizheng Pan**, Jing Liu, Haoyu He, Jianfei Cai, Bohan Zhuang\#

[[Paper](https://arxiv.org/abs/2307.00154)][[HuggingFace](https://huggingface.co/ziplab)][[Code](https://github.com/ziplab/SN-Netv2)]


- **QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models**

**Jing Liu**, Ruihao Gong, Xiuying Wei, Zhiwei Dong, Jianfei Cai, Bohan Zhuang\#

[[OpenReview](https://openreview.net/forum?id=FIplmUWdm3)][[Code-1](https://github.com/ModelTC/QLLM)][[Code-2](https://github.com/ziplab/QLLM)]  **ICLR 2024**


- **EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models**

**Yefei He**, Jing Liu, Weijia Wu, Hong Zhou\#, Bohan Zhuang\#

[[OpenReview](https://openreview.net/forum?id=UmMa3UNDAz)][[Code](https://github.com/ThisisBillhe/EfficientDM)] **ICLR 2024 (Spotlight, Top 5%)**


- **Object-Aware Inversion and Reassembly for Image Editing**

**Zhen Yang**, Ganggui Ding, Wen Wang, Hao Chen\#, Bohan Zhuang\#, Chunhua Shen

[[OpenReview](https://openreview.net/forum?id=dpcVXiMlcv)][[Project](https://github.com/aim-uofa/OIR)] **ICLR 2024**


- **Efficient Stitchable Task Adaptation**

**Haoyu He**, Zizheng Pan, Jing Liu, Jianfei Cai, Bohan Zhuang\#

[[Paper](https://arxiv.org/abs/2311.17352)][[Code](https://github.com/ziplab/Stitched_LLaMA)]  **CVPR 2024**


- **ModaVerse: Efficiently Transforming Modalities with LLMs**

**Xinyu Wang**, Bohan Zhuang, Qi Wu 

[[Paper](https://arxiv.org/abs/2401.06395)][[Code](https://github.com/xinke-wang/ModaVerse)]   **CVPR 2024**




**2023**


- **Stitchable Neural Networks**

**Zizheng Pan**, Jianfei Cai, Bohan Zhuang\#

[[Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Pan_Stitchable_Neural_Networks_CVPR_2023_paper.pdf)][[Project](https://snnet.github.io/)][[Code](https://github.com/ziplab/SN-Net)] **CVPR 2023 (Highlight, Top 2.5%)** 


- **PTQD: Accurate Post-Training Quantization for Diffusion Models**

**Yefei He**, Luping Liu, Jing Liu, Weijia Wu, Hong Zhou\#, Bohan Zhuang\#

[[OpenReview](https://openreview.net/forum?id=Y3g1PV5R9l)][[Code](https://github.com/ziplab/PTQD)] **NeurIPS 2023**


- **Mask Propagation for Efficient Video Semantic Segmentation**

**Yuetian Weng**, Mingfei Han, Haoyu He, Mingjie Li, Xiaojun Chang, Bohan Zhuang\#

[[OpenReview](https://openreview.net/forum?id=6ljXBlojde)][[Code](https://github.com/ziplab/MPVSS)]  **NeurIPS 2023**


- **Efficient Test-Time Adaptation for Super-Resolution with Second-Order Degradation and Reconstruction**

**Zeshuai Deng**, Zhuokun Chen, Shuaicheng Niu, Thomas H. Li, Bohan Zhuang\#, Mingkui Tan\#

[[OpenReview](https://openreview.net/forum?id=IZRlMABK4l)][[Code](https://github.com/dengzeshuai/srtta)]  **NeurIPS 2023**


- **Sensitivity-Aware Visual Parameter-Efficient Fine-Tuning**

**Haoyu He**, Jianfei Cai, Jing Zhang, Dacheng Tao, Bohan Zhuang\#

[[Paper](https://openaccess.thecvf.com/content/ICCV2023/papers/He_Sensitivity-Aware_Visual_Parameter-Efficient_Fine-Tuning_ICCV_2023_paper.pdf)][[Code](https://github.com/ziplab/SPT)] **ICCV 2023 (Oral)**


- **BiViT: Extremely Compressed Binary Vision Transformer**

**Yefei He**, Zhenyu Lou, Luoming Zhang, Jing Liu, Weijia Wu, Hong Zhou\#, Bohan Zhuang\#

[[Paper](https://openaccess.thecvf.com/content/ICCV2023/papers/He_BiViT_Extremely_Compressed_Binary_Vision_Transformers_ICCV_2023_paper.pdf)] **ICCV 2023**


- **Dynamic Focus-aware Positional Queries for Semantic Segmentation**

**Haoyu He**, Jianfei Cai, Zizheng Pan, Jing Liu, Jing Zhang, Dacheng Tao, Bohan Zhuang\#

[[Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/He_Dynamic_Focus-Aware_Positional_Queries_for_Semantic_Segmentation_CVPR_2023_paper.pdf)][[Code](https://github.com/ziplab/FASeg)] **CVPR 2023**


- **Pruning Self-attentions into Convolutional Layers in Single Path**

**Haoyu He**, Jing Liu, Zizheng Pan, Jianfei Cai, Jing Zhang, Dacheng Tao, Bohan Zhuang\#

[[Paper](https://arxiv.org/abs/2111.11802)][[Code](https://github.com/zip-group/SPViT)] **TPAMI 2023**


- **Single-path Bit Sharing for Automatic Loss-aware Model Compression**

**Jing Liu**, Bohan Zhuang, Peng Chen, Chunhua Shen, Jianfei Cai, Mingkui Tan

[[Paper](https://arxiv.org/abs/2101.04935)]  **TPAMI 2023**


- **End-to-end One-shot Human Parsing**

**Haoyu He**, Jing Zhang, Bohan Zhuang, Jianfei Cai, Dacheng Tao

[[Paper](https://arxiv.org/abs/2105.01241)][[Code](https://github.com/Charleshhy/One-shot-Human-Parsing/stargazers)] **TPAMI 2023**


- **A Survey on Efficient Training of Transformers**

**Bohan Zhuang**\#, Jing Liu, Zizheng Pan, Haoyu He, Yuetian Weng, Chunhua Shen

[[Paper](https://arxiv.org/abs/2302.01107)] **IJCAI 2023 Survey Track**


- **SwitchGPT: Adapting Large Language Models for Non-Text Outputs**

**Xinyu Wang**, Bohan Zhuang, Qi Wu

[[Paper](https://arxiv.org/abs/2309.07623)]



**2022**

- **EcoFormer: Energy-Saving Attention with Linear Complexity**  

**Jing Liu**\*, **Zizheng Pan**\*, Haoyu He, Jianfei Cai, Bohan Zhuang\#

[[OpenReview](https://openreview.net/forum?id=MK_130d4Y0)][[Code](https://github.com/ziplab/EcoFormer)]  **NeurIPS 2022 (Spotlight, Top 3%)**  


- **Fast Vision Transformers with HiLo Attention**

**Zizheng Pan**, Jianfei Cai, Bohan Zhuang\#

[[OpenReview](https://openreview.net/forum?id=Pyd6Rh9r1OT)][[Code](https://github.com/ziplab/LITv2)]  **NeurIPS 2022 (Spotlight, Top 3%)**



- **An Efficient Spatio-Temporal Pyramid Transformer for Action Detection**

**Yuetian Weng**, Zizheng Pan, Mingfei Han, Xiaojun Chang, Bohan Zhuang\#

[[Paper](https://link.springer.com/content/pdf/10.1007/978-3-031-19830-4_21.pdf)][[Code](https://github.com/ziplab/STPT)]   **ECCV 2022**



- **Automated Progressive Learning for Efficient Training of Vision Transformers**

**Changlin Li**, Bohan Zhuang\#, Guangrun Wang, Xiaodan Liang, Xiaojun Chang, Yi Yang

[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Automated_Progressive_Learning_for_Efficient_Training_of_Vision_Transformers_CVPR_2022_paper.pdf)][[Code](https://github.com/changlin31/AutoProg)]  **CVPR 2022**


- **Less is More: Pay Less Attention in Vision Transformers**

**Zizheng Pan**, Bohan Zhuang\#, Haoyu He, Jing Liu, Jianfei Cai

[[paper](https://ojs.aaai.org/index.php/AAAI/article/view/20099)] [[Code](https://github.com/zhuang-group/LIT)] **AAAI 2022**



- **Structured Binary Neural Networks for Image Recognition**

**Bohan Zhuang**, Chunhua Shen, Mingkui Tan, Peng Chen, Lingqiao Liu, Ian Reid

[[paper](https://link.springer.com/article/10.1007/s11263-022-01638-0)]  **IJCV 2022**


- **Mesa: A Memory-saving Training Framework for Transformers**

**Zizheng Pan**, Peng Chen, Haoyu He, Jing Liu, Jianfei Cai, Bohan Zhuang\#

[[Paper](https://arxiv.org/abs/2111.11124)][[Code](https://github.com/zip-group/Mesa)]



- **Sharpness-aware Quantization for Deep Neural Networks**

**Jing Liu**, Jianfei Cai, Bohan Zhuang\#

[[Paper](https://arxiv.org/abs/2111.12273)][[Code](https://github.com/zip-group/SAQ)]


- **FocusFormer: Focusing on What We Need via Architecture Sampler**

**Jing Liu**, Jianfei Cai, Bohan Zhuang\#

[[Paper](https://arxiv.org/abs/2208.10861)]


- **Rapid Elastic Architecture Search under Specialized Classes and Resource Constraints**

**Jing Liu**, Bohan Zhuang\#, Mingkui Tan, Xu Liu, Dinh Phung, Yuanqing Li, Jianfei Cai

[[Paper](https://arxiv.org/abs/2108.01224)]




**2021**


- **Scalable Vision Transformers with Hierarchical Pooling**

**Zizheng Pan**, Bohan Zhuang\#, **Jing Liu**, **Haoyu He**, Jianfei Cai

[[Paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Pan_Scalable_Vision_Transformers_With_Hierarchical_Pooling_ICCV_2021_paper.pdf)][[Code](https://github.com/zhuang-group/HVT)]  **ICCV 2021**


- **FATNN: Fast and Accurate Ternary Neural Networks**

**Peng Chen**\*,  Bohan Zhuang\*, Chunhua Shen

[[Paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_FATNN_Fast_and_Accurate_Ternary_Neural_Networks_ICCV_2021_paper.pdf)][[Code](https://github.com/zhuang-group/QTool)]   **ICCV 2021**


- **Effective Training of Convolutional Neural Networks with Low-bitwidth Weights and Activations**

**Bohan Zhuang**\*, Mingkui Tan\*, **Jing Liu**\*, Ian Reid, Chunhua Shen\#

[[Paper](https://arxiv.org/pdf/1908.04680.pdf)][[Code](https://github.com/bohanzhuang/Towards-Effective-Low-bitwidth-Convolutional-Neural-Networks)] **TPAMI**


- **Discrimination-aware Network Pruning for Deep Model Compression**

**Jing Liu**\*, Bohan Zhuang\*, Zhuangwei Zhuang\*, Yong Guo, Junzhou Huang, Jinhui Zhu, Mingkui Tan\#

[[Paper](https://ieeexplore.ieee.org/document/9384353)][[Code](https://github.com/SCUT-AILab/DCP)] **TPAMI**


- **AQD: Towards Accurate Fully-Quantized Object Detection**

**Peng Chen**\*, **Jing Liu**\*, Bohan Zhuang\#, Mingkui Tan, Chunhua Shen

[[Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_AQD_Towards_Accurate_Quantized_Object_Detection_CVPR_2021_paper.pdf)][[Code](https://github.com/zhuang-group/QTool)]  **CVPR 2021 (Oral)**


- **SA-BNN: State-Aware Binary Neural Network**

Chunlei Liu\*, **Peng Chen**\*, Bohan Zhuang\*, Chunhua Shen, Baochang Zhang, Wenrui Ding

[[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/16306)] **AAAI 2021**







